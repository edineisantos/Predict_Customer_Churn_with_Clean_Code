{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1066532-6dac-49eb-87e1-943490cb6f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "import joblib\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import plot_roc_curve, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "245141ed-966f-42fe-a573-493afa23ee2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import (\n",
    "    file_path, eda_images_path,\n",
    "    category_list_constant, response_constant,\n",
    "    keep_cols, results_images_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce6aa986-307a-45d8-9a9f-7734b16e6ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(file_path):\n",
    "    '''\n",
    "    returns dataframe for the csv found at pth\n",
    "\n",
    "    input:\n",
    "            pth: a path to the csv\n",
    "    output:\n",
    "            dataframe: pandas dataframe\n",
    "    '''\n",
    "\n",
    "    dataframe = pd.read_csv(file_path)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a642219e-185e-40da-80ed-2ae8f6dc786b",
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_df = import_data(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "64ca3668-47d0-4ad2-9d1a-42ccabb7308a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'invalid path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m churn_df \u001b[38;5;241m=\u001b[39m \u001b[43mimport_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minvalid path\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 11\u001b[0m, in \u001b[0;36mimport_data\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimport_data\u001b[39m(file_path):\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m    returns dataframe for the csv found at pth\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m            dataframe: pandas dataframe\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m     dataframe \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dataframe\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/pandas/io/parsers.py:610\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    605\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    606\u001b[0m     dialect, delimiter, delim_whitespace, engine, sep, defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m    607\u001b[0m )\n\u001b[1;32m    608\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 610\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/pandas/io/parsers.py:462\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    459\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    461\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 462\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/pandas/io/parsers.py:819\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwds:\n\u001b[1;32m    817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 819\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/pandas/io/parsers.py:1050\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1046\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1047\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown engine: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mengine\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (valid options are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmapping\u001b[38;5;241m.\u001b[39mkeys()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1048\u001b[0m     )\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;66;03m# error: Too many arguments for \"ParserBase\"\u001b[39;00m\n\u001b[0;32m-> 1050\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/pandas/io/parsers.py:1867\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1864\u001b[0m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musecols\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39musecols\n\u001b[1;32m   1866\u001b[0m \u001b[38;5;66;03m# open handles\u001b[39;00m\n\u001b[0;32m-> 1867\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open_handles\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/pandas/io/parsers.py:1362\u001b[0m, in \u001b[0;36mParserBase._open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1358\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_handles\u001b[39m(\u001b[38;5;28mself\u001b[39m, src: FilePathOrBuffer, kwds: Dict[\u001b[38;5;28mstr\u001b[39m, Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;124;03m    Let the readers open IOHanldes after they are done with their potential raises.\u001b[39;00m\n\u001b[1;32m   1361\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1362\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1363\u001b[0m \u001b[43m        \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1364\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1365\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1366\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1367\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1368\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1369\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/pandas/io/common.py:642\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    640\u001b[0m         errors \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    641\u001b[0m     \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 642\u001b[0m     handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    643\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    644\u001b[0m \u001b[43m        \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    650\u001b[0m     \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    651\u001b[0m     handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'invalid path'"
     ]
    }
   ],
   "source": [
    "churn_df = import_data(\"invalid path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "852ddcb9-ce01-45b3-8605-e09e7467f52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_df['Churn'] = churn_df['Attrition_Flag'].apply(lambda val: 0 if val == \"Existing Customer\" else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936f3e1e-1dc7-45aa-8648-1867bde3c737",
   "metadata": {},
   "source": [
    "### encoder helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6dc9a36-16eb-4bfa-9e02-c00e4adc1bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_helper(dataframe, category_list, response=response_constant):\n",
    "    '''\n",
    "    Helper function to turn each categorical column into a new column with\n",
    "    proportion of churn for each category\n",
    "\n",
    "    input:\n",
    "        dataframe: pandas DataFrame\n",
    "        category_list: list of columns that contain categorical features\n",
    "        response: string of response name [optional argument that could\n",
    "        be used for naming variables or index y column]\n",
    "\n",
    "    output:\n",
    "        DataFrame with new columns\n",
    "    '''\n",
    "    for category in category_list:\n",
    "        category_groups = dataframe.groupby(category).mean()[response]\n",
    "        new_column_name = f\"{category}_{response}\"\n",
    "\n",
    "        dataframe[new_column_name] = dataframe[category].apply(\n",
    "            lambda val, category_groups=category_groups: category_groups.loc[val])\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5c9566a-494e-48f3-b332-6b1a8949941d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'CLIENTNUM', 'Attrition_Flag', 'Customer_Age', 'Gender',\n",
       "       'Dependent_count', 'Education_Level', 'Marital_Status',\n",
       "       'Income_Category', 'Card_Category', 'Months_on_book',\n",
       "       'Total_Relationship_Count', 'Months_Inactive_12_mon',\n",
       "       'Contacts_Count_12_mon', 'Credit_Limit', 'Total_Revolving_Bal',\n",
       "       'Avg_Open_To_Buy', 'Total_Amt_Chng_Q4_Q1', 'Total_Trans_Amt',\n",
       "       'Total_Trans_Ct', 'Total_Ct_Chng_Q4_Q1', 'Avg_Utilization_Ratio',\n",
       "       'Churn', 'Gender_Churn', 'Education_Level_Churn',\n",
       "       'Marital_Status_Churn', 'Income_Category_Churn', 'Card_Category_Churn'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your DataFrame\n",
    "df = churn_df.copy()\n",
    "\n",
    "# Calling the function\n",
    "df = encoder_helper(df, category_list_constant)\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5eec83-fa5a-412e-a421-7d2c5116cf2b",
   "metadata": {},
   "source": [
    "### perform_feature_engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0dcc1eb6-f9ce-4c40-9a64-76cc00a61762",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d17897a-68c1-40cc-94ac-3a0f4d71a2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = churn_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce61c687-bc8b-4eff-aee9-919d1a9aa7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Churn']\n",
    "X = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c99f37e0-af55-465e-9fba-9358b040bd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New columns\n",
    "df = encoder_helper(df, category_list_constant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76e1432e-b01e-4c41-a075-889b454a3282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>CLIENTNUM</th>\n",
       "      <th>Attrition_Flag</th>\n",
       "      <th>Customer_Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Dependent_count</th>\n",
       "      <th>Education_Level</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Income_Category</th>\n",
       "      <th>Card_Category</th>\n",
       "      <th>...</th>\n",
       "      <th>Total_Trans_Amt</th>\n",
       "      <th>Total_Trans_Ct</th>\n",
       "      <th>Total_Ct_Chng_Q4_Q1</th>\n",
       "      <th>Avg_Utilization_Ratio</th>\n",
       "      <th>Churn</th>\n",
       "      <th>Gender_Churn</th>\n",
       "      <th>Education_Level_Churn</th>\n",
       "      <th>Marital_Status_Churn</th>\n",
       "      <th>Income_Category_Churn</th>\n",
       "      <th>Card_Category_Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>768805383</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>45</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>High School</td>\n",
       "      <td>Married</td>\n",
       "      <td>$60K - $80K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>...</td>\n",
       "      <td>1144</td>\n",
       "      <td>42</td>\n",
       "      <td>1.625</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0</td>\n",
       "      <td>0.146152</td>\n",
       "      <td>0.152012</td>\n",
       "      <td>0.151269</td>\n",
       "      <td>0.134807</td>\n",
       "      <td>0.160979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>818770008</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>49</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Single</td>\n",
       "      <td>Less than $40K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>...</td>\n",
       "      <td>1291</td>\n",
       "      <td>33</td>\n",
       "      <td>3.714</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0</td>\n",
       "      <td>0.173572</td>\n",
       "      <td>0.155691</td>\n",
       "      <td>0.169414</td>\n",
       "      <td>0.171862</td>\n",
       "      <td>0.160979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>713982108</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>51</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Married</td>\n",
       "      <td>$80K - $120K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>...</td>\n",
       "      <td>1887</td>\n",
       "      <td>20</td>\n",
       "      <td>2.333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.146152</td>\n",
       "      <td>0.155691</td>\n",
       "      <td>0.151269</td>\n",
       "      <td>0.157655</td>\n",
       "      <td>0.160979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>769911858</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>40</td>\n",
       "      <td>F</td>\n",
       "      <td>4</td>\n",
       "      <td>High School</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Less than $40K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>...</td>\n",
       "      <td>1171</td>\n",
       "      <td>20</td>\n",
       "      <td>2.333</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0</td>\n",
       "      <td>0.173572</td>\n",
       "      <td>0.152012</td>\n",
       "      <td>0.172230</td>\n",
       "      <td>0.171862</td>\n",
       "      <td>0.160979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>709106358</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>40</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>Uneducated</td>\n",
       "      <td>Married</td>\n",
       "      <td>$60K - $80K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>...</td>\n",
       "      <td>816</td>\n",
       "      <td>28</td>\n",
       "      <td>2.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.146152</td>\n",
       "      <td>0.159381</td>\n",
       "      <td>0.151269</td>\n",
       "      <td>0.134807</td>\n",
       "      <td>0.160979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  CLIENTNUM     Attrition_Flag  Customer_Age Gender  \\\n",
       "0           0  768805383  Existing Customer            45      M   \n",
       "1           1  818770008  Existing Customer            49      F   \n",
       "2           2  713982108  Existing Customer            51      M   \n",
       "3           3  769911858  Existing Customer            40      F   \n",
       "4           4  709106358  Existing Customer            40      M   \n",
       "\n",
       "   Dependent_count Education_Level Marital_Status Income_Category  \\\n",
       "0                3     High School        Married     $60K - $80K   \n",
       "1                5        Graduate         Single  Less than $40K   \n",
       "2                3        Graduate        Married    $80K - $120K   \n",
       "3                4     High School        Unknown  Less than $40K   \n",
       "4                3      Uneducated        Married     $60K - $80K   \n",
       "\n",
       "  Card_Category  ...  Total_Trans_Amt  Total_Trans_Ct  Total_Ct_Chng_Q4_Q1  \\\n",
       "0          Blue  ...             1144              42                1.625   \n",
       "1          Blue  ...             1291              33                3.714   \n",
       "2          Blue  ...             1887              20                2.333   \n",
       "3          Blue  ...             1171              20                2.333   \n",
       "4          Blue  ...              816              28                2.500   \n",
       "\n",
       "   Avg_Utilization_Ratio  Churn  Gender_Churn  Education_Level_Churn  \\\n",
       "0                  0.061      0      0.146152               0.152012   \n",
       "1                  0.105      0      0.173572               0.155691   \n",
       "2                  0.000      0      0.146152               0.155691   \n",
       "3                  0.760      0      0.173572               0.152012   \n",
       "4                  0.000      0      0.146152               0.159381   \n",
       "\n",
       "   Marital_Status_Churn  Income_Category_Churn  Card_Category_Churn  \n",
       "0              0.151269               0.134807             0.160979  \n",
       "1              0.169414               0.171862             0.160979  \n",
       "2              0.151269               0.157655             0.160979  \n",
       "3              0.172230               0.171862             0.160979  \n",
       "4              0.151269               0.134807             0.160979  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aebba6e4-b1f4-4171-aa35-3182e91fad6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[keep_cols] = df[keep_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85412bc0-ce34-40d5-bbeb-0bd851e1872c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer_Age</th>\n",
       "      <th>Dependent_count</th>\n",
       "      <th>Months_on_book</th>\n",
       "      <th>Total_Relationship_Count</th>\n",
       "      <th>Months_Inactive_12_mon</th>\n",
       "      <th>Contacts_Count_12_mon</th>\n",
       "      <th>Credit_Limit</th>\n",
       "      <th>Total_Revolving_Bal</th>\n",
       "      <th>Avg_Open_To_Buy</th>\n",
       "      <th>Total_Amt_Chng_Q4_Q1</th>\n",
       "      <th>Total_Trans_Amt</th>\n",
       "      <th>Total_Trans_Ct</th>\n",
       "      <th>Total_Ct_Chng_Q4_Q1</th>\n",
       "      <th>Avg_Utilization_Ratio</th>\n",
       "      <th>Gender_Churn</th>\n",
       "      <th>Education_Level_Churn</th>\n",
       "      <th>Marital_Status_Churn</th>\n",
       "      <th>Income_Category_Churn</th>\n",
       "      <th>Card_Category_Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12691.0</td>\n",
       "      <td>777</td>\n",
       "      <td>11914.0</td>\n",
       "      <td>1.335</td>\n",
       "      <td>1144</td>\n",
       "      <td>42</td>\n",
       "      <td>1.625</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.146152</td>\n",
       "      <td>0.152012</td>\n",
       "      <td>0.151269</td>\n",
       "      <td>0.134807</td>\n",
       "      <td>0.160979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8256.0</td>\n",
       "      <td>864</td>\n",
       "      <td>7392.0</td>\n",
       "      <td>1.541</td>\n",
       "      <td>1291</td>\n",
       "      <td>33</td>\n",
       "      <td>3.714</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.173572</td>\n",
       "      <td>0.155691</td>\n",
       "      <td>0.169414</td>\n",
       "      <td>0.171862</td>\n",
       "      <td>0.160979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3418.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3418.0</td>\n",
       "      <td>2.594</td>\n",
       "      <td>1887</td>\n",
       "      <td>20</td>\n",
       "      <td>2.333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.146152</td>\n",
       "      <td>0.155691</td>\n",
       "      <td>0.151269</td>\n",
       "      <td>0.157655</td>\n",
       "      <td>0.160979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3313.0</td>\n",
       "      <td>2517</td>\n",
       "      <td>796.0</td>\n",
       "      <td>1.405</td>\n",
       "      <td>1171</td>\n",
       "      <td>20</td>\n",
       "      <td>2.333</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.173572</td>\n",
       "      <td>0.152012</td>\n",
       "      <td>0.172230</td>\n",
       "      <td>0.171862</td>\n",
       "      <td>0.160979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4716.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4716.0</td>\n",
       "      <td>2.175</td>\n",
       "      <td>816</td>\n",
       "      <td>28</td>\n",
       "      <td>2.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.146152</td>\n",
       "      <td>0.159381</td>\n",
       "      <td>0.151269</td>\n",
       "      <td>0.134807</td>\n",
       "      <td>0.160979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Customer_Age  Dependent_count  Months_on_book  Total_Relationship_Count  \\\n",
       "0            45                3              39                         5   \n",
       "1            49                5              44                         6   \n",
       "2            51                3              36                         4   \n",
       "3            40                4              34                         3   \n",
       "4            40                3              21                         5   \n",
       "\n",
       "   Months_Inactive_12_mon  Contacts_Count_12_mon  Credit_Limit  \\\n",
       "0                       1                      3       12691.0   \n",
       "1                       1                      2        8256.0   \n",
       "2                       1                      0        3418.0   \n",
       "3                       4                      1        3313.0   \n",
       "4                       1                      0        4716.0   \n",
       "\n",
       "   Total_Revolving_Bal  Avg_Open_To_Buy  Total_Amt_Chng_Q4_Q1  \\\n",
       "0                  777          11914.0                 1.335   \n",
       "1                  864           7392.0                 1.541   \n",
       "2                    0           3418.0                 2.594   \n",
       "3                 2517            796.0                 1.405   \n",
       "4                    0           4716.0                 2.175   \n",
       "\n",
       "   Total_Trans_Amt  Total_Trans_Ct  Total_Ct_Chng_Q4_Q1  \\\n",
       "0             1144              42                1.625   \n",
       "1             1291              33                3.714   \n",
       "2             1887              20                2.333   \n",
       "3             1171              20                2.333   \n",
       "4              816              28                2.500   \n",
       "\n",
       "   Avg_Utilization_Ratio  Gender_Churn  Education_Level_Churn  \\\n",
       "0                  0.061      0.146152               0.152012   \n",
       "1                  0.105      0.173572               0.155691   \n",
       "2                  0.000      0.146152               0.155691   \n",
       "3                  0.760      0.173572               0.152012   \n",
       "4                  0.000      0.146152               0.159381   \n",
       "\n",
       "   Marital_Status_Churn  Income_Category_Churn  Card_Category_Churn  \n",
       "0              0.151269               0.134807             0.160979  \n",
       "1              0.169414               0.171862             0.160979  \n",
       "2              0.151269               0.157655             0.160979  \n",
       "3              0.172230               0.171862             0.160979  \n",
       "4              0.151269               0.134807             0.160979  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9efbf633-2944-4e9d-adea-66d940e68404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split \n",
    "features_train, features_test, target_train, target_test = train_test_split(X, y, test_size= 0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6cd612fc-e25e-46e8-be1d-a7636090b47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7088, 19)\n",
      "(3039, 19)\n",
      "(7088,)\n",
      "(3039,)\n"
     ]
    }
   ],
   "source": [
    "print(features_train.shape)\n",
    "print(features_test.shape)\n",
    "print(target_train.shape)\n",
    "print(target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593e63d6-46c4-4e56-a930-6a38e0d28316",
   "metadata": {},
   "source": [
    "### train_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "94134b94-5ee8-4cad-a094-6d9e0fa35181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training rfc...\n",
      "Training lrc...\n",
      "Getting predictions...\n",
      "...........................................\n",
      "Logistic regression results:\n",
      "Test results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93      2543\n",
      "           1       0.71      0.45      0.55       496\n",
      "\n",
      "    accuracy                           0.88      3039\n",
      "   macro avg       0.81      0.71      0.74      3039\n",
      "weighted avg       0.87      0.88      0.87      3039\n",
      "\n",
      "Train results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.94      5957\n",
      "           1       0.72      0.50      0.59      1131\n",
      "\n",
      "    accuracy                           0.89      7088\n",
      "   macro avg       0.82      0.73      0.76      7088\n",
      "weighted avg       0.88      0.89      0.88      7088\n",
      "\n",
      "Random forest results:\n",
      "Test results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98      2543\n",
      "           1       0.93      0.80      0.86       496\n",
      "\n",
      "    accuracy                           0.96      3039\n",
      "   macro avg       0.95      0.90      0.92      3039\n",
      "weighted avg       0.96      0.96      0.96      3039\n",
      "\n",
      "Train results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5957\n",
      "           1       1.00      1.00      1.00      1131\n",
      "\n",
      "    accuracy                           1.00      7088\n",
      "   macro avg       1.00      1.00      1.00      7088\n",
      "weighted avg       1.00      1.00      1.00      7088\n",
      "\n",
      "...........................................\n",
      "Saving roc_curve_result.png...\n",
      "CPU times: user 5min 2s, sys: 3.93 s, total: 5min 6s\n",
      "Wall time: 4min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cv_rfc, lrc, target_data = train_models(features_train, features_test, target_train, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd1370e9-6c54-4f85-9eb3-5a23d8157f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aef23615-2a54-4ed4-a18a-1f57be7ee238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving logistic_results.png...\n",
      "Saving rf_results.png...\n",
      "CPU times: user 447 ms, sys: 40.1 ms, total: 487 ms\n",
      "Wall time: 483 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "classification_report_image(target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5bcf9e3f-c313-47ee-a404-e7ca8aee5f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving feature_importances.png...\n",
      "Feature importances saved successfully.\n",
      "CPU times: user 1min 31s, sys: 525 ms, total: 1min 31s\n",
      "Wall time: 1min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "feature_importance_plot(cv_rfc, features_test, results_images_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3fdf94fe-090b-41f5-aa61-cf53ef726015",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(features_train, features_test, target_train, target_test):\n",
    "    '''\n",
    "    train, store model results: images + scores, and store models\n",
    "    input:\n",
    "              features_train: features training data\n",
    "              features_test: features testing data\n",
    "              target_train: target training data\n",
    "              target_test: target testing data\n",
    "    output:\n",
    "              None\n",
    "    '''\n",
    "    # train models\n",
    "    rfc = RandomForestClassifier(random_state=42)\n",
    "    lrc = LogisticRegression(solver='lbfgs', max_iter=3000)\n",
    "    param_grid = { \n",
    "    'n_estimators': [200, 500],\n",
    "    'max_features': ['auto', 'sqrt'],\n",
    "    'max_depth' : [4,5,100],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "    }\n",
    "    cv_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv=5)\n",
    "    print(\"Training rfc...\")\n",
    "    cv_rfc.fit(features_train, target_train)\n",
    "    print(\"Training lrc...\")\n",
    "    lrc.fit(features_train, target_train)\n",
    "\n",
    "    # Get the predictions\n",
    "    print(\"Getting predictions...\")\n",
    "    # Randon forest\n",
    "    target_train_preds_rf = cv_rfc.best_estimator_.predict(features_train)\n",
    "    target_test_preds_rf = cv_rfc.best_estimator_.predict(features_test)\n",
    "    # Logistic Regression\n",
    "    target_train_preds_lr = lrc.predict(features_train)\n",
    "    target_test_preds_lr = lrc.predict(features_test)\n",
    "    print(\"...........................................\")\n",
    "\n",
    "    # Scores\n",
    "    print('Logistic regression results:')\n",
    "    print('Test results:')\n",
    "    print(classification_report(target_test, target_test_preds_lr))\n",
    "    print('Train results:')\n",
    "    print(classification_report(target_train, target_train_preds_lr))\n",
    "    print('Random forest results:')\n",
    "    print('Test results:')\n",
    "    print(classification_report(target_test, target_test_preds_rf))\n",
    "    print('Train results:')\n",
    "    print(classification_report(target_train, target_train_preds_rf))\n",
    "    print(\"...........................................\")\n",
    "\n",
    "    # roc_curve_result.png\n",
    "    print(\"Saving roc_curve_result.png...\")\n",
    "    # Create a new figure for the ROC curve\n",
    "    plt.ioff()\n",
    "    fig, ax_fig = plt.subplots(figsize=(15, 8))    \n",
    "    # Plot ROC curve for each model\n",
    "    plot_roc_curve(lrc, features_test, target_test, ax=ax_fig, \n",
    "                   alpha=0.8, name='Logistic Regression')\n",
    "    plot_roc_curve(cv_rfc.best_estimator_, features_test, target_test, \n",
    "                   ax=ax_fig, alpha=0.8, name='Random Forest')    \n",
    "    # Add title to the plot\n",
    "    plt.title(\"ROC Curve\")    \n",
    "    # Save the plot\n",
    "    save_path = f\"{results_images_path}roc_curve_result.png\"\n",
    "    plt.savefig(save_path)\n",
    "    \n",
    "    # Close the plot\n",
    "    plt.close(fig)\n",
    "    del fig\n",
    "    del ax_fig\n",
    "\n",
    "    # save best model\n",
    "    joblib.dump(cv_rfc.best_estimator_, './models/rfc_model.pkl')\n",
    "    joblib.dump(lrc, './models/logistic_model.pkl')\n",
    "\n",
    "    # Save the target data in a list\n",
    "    target_data = [target_train, target_test, target_train_preds_lr, \n",
    "                   target_train_preds_rf, target_test_preds_lr, target_test_preds_rf]\n",
    "\n",
    "    print(\"Train models process completed!\")\n",
    "\n",
    "    return cv_rfc, lrc, target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "428b95fe-7177-4a30-88b0-5becfee19d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results images\n",
    "#def classification_report_image(target_train,\n",
    "#                                target_test,\n",
    "#                                target_train_preds_lr,\n",
    "#                                target_train_preds_rf,\n",
    "#                                target_test_preds_lr,\n",
    "#                                target_test_preds_rf):\n",
    "def classification_report_image(target_data):\n",
    "    '''\n",
    "    Produces classification report for training and testing results and stores\n",
    "    the report as an image in the images folder.\n",
    "\n",
    "    input:\n",
    "            target_data: A list or tuple containing six elements:\n",
    "                - target_train: training response values\n",
    "                - target_test: test response values\n",
    "                - target_train_preds_lr: training predictions from logistic regression\n",
    "                - target_train_preds_rf: training predictions from random forest\n",
    "                - target_test_preds_lr: test predictions from logistic regression\n",
    "                - target_test_preds_rf: test predictions from random forest\n",
    "\n",
    "    output:\n",
    "             None\n",
    "    '''\n",
    "\n",
    "    # Split up the target_data in new variables\n",
    "    (\n",
    "    target_train, target_test, target_train_preds_lr, \n",
    "    target_train_preds_rf, target_test_preds_lr, target_test_preds_rf\n",
    "    ) = target_data\n",
    "\n",
    "    \n",
    "    # logistic_results.png\n",
    "    print(\"Saving logistic_results.png...\")\n",
    "    plt.figure(figsize=(15, 8))  # Create a new figure\n",
    "    \n",
    "    plt.text(\n",
    "        0.01, 1.0,\n",
    "        'Logistic Regression Train',\n",
    "        {'fontsize': 10},\n",
    "        fontproperties='monospace'\n",
    "    )\n",
    "    \n",
    "    plt.text(\n",
    "        0.01, 0.7,\n",
    "        str(classification_report(target_train, target_train_preds_lr)),\n",
    "        {'fontsize': 10},\n",
    "        fontproperties='monospace'\n",
    "    )\n",
    "    \n",
    "    plt.text(\n",
    "        0.01, 0.4,\n",
    "        'Logistic Regression Test',\n",
    "        {'fontsize': 10},\n",
    "        fontproperties='monospace'\n",
    "    )\n",
    "    \n",
    "    plt.text(\n",
    "        0.01, 0.1,\n",
    "        str(classification_report(target_test, target_test_preds_lr)),\n",
    "        {'fontsize': 10},\n",
    "        fontproperties='monospace'\n",
    "    )\n",
    "    \n",
    "    plt.axis('off')\n",
    "    plt.savefig(f\"{results_images_path}/logistic_results.png\")\n",
    "    plt.close()  # Close the figure to free up the resources\n",
    "    \n",
    "    # rf_results.png\n",
    "    print(\"Saving rf_results.png...\")\n",
    "    plt.figure(figsize=(15, 8))  # Create a new figure\n",
    "    \n",
    "    plt.text(\n",
    "        0.01, 1.0,\n",
    "        'Random Forest Train',\n",
    "        {'fontsize': 10},\n",
    "        fontproperties='monospace'\n",
    "    )\n",
    "    \n",
    "    plt.text(\n",
    "        0.01, 0.7,\n",
    "        str(classification_report(target_test, target_test_preds_rf)),\n",
    "        {'fontsize': 10},\n",
    "        fontproperties='monospace'\n",
    "    )\n",
    "    \n",
    "    plt.text(\n",
    "        0.01, 0.4,\n",
    "        'Random Forest Test',\n",
    "        {'fontsize': 10},\n",
    "        fontproperties='monospace'\n",
    "    )\n",
    "    \n",
    "    plt.text(\n",
    "        0.01, 0.1,\n",
    "        str(classification_report(target_train, target_train_preds_rf)),\n",
    "        {'fontsize': 10},\n",
    "        fontproperties='monospace'\n",
    "    )\n",
    "    \n",
    "    plt.axis('off')\n",
    "    plt.savefig(f\"{results_images_path}/rf_results.png\")\n",
    "    plt.close()  # Close the figure to free up the resources    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2b750a5-9b08-446e-94b1-282f60a2c93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance_plot(model, feature_data, output_path):\n",
    "    '''\n",
    "    Creates and stores the feature importances in path.\n",
    "    Inputs:\n",
    "        model: model object containing feature_importances_\n",
    "        feature_data: pandas DataFrame of X values\n",
    "        output_path: path to store the figure\n",
    "    Output:\n",
    "        None\n",
    "    '''\n",
    "    print(\"Saving feature_importances.png...\")\n",
    "\n",
    "    # Create a figure to hold the SHAP plot\n",
    "    explainer = shap.TreeExplainer(model.best_estimator_)\n",
    "    shap_values = explainer.shap_values(feature_data)\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    shap.summary_plot(shap_values, feature_data, plot_type=\"bar\", \n",
    "                      show=False, plot_size = (20,5))\n",
    "    shap_plot_path = os.path.join(output_path, \"shap_plot.png\")    \n",
    "    plt.savefig(shap_plot_path)\n",
    "    plt.close()\n",
    "\n",
    "    # Create and Save Feature Importance plot\n",
    "    importances = model.best_estimator_.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    names = [feature_data.columns[i] for i in indices]\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    plt.bar(range(feature_data.shape[1]), importances[indices])    \n",
    "    # Reduce font size for x-axis labels\n",
    "    plt.xticks(range(feature_data.shape[1]), names, rotation=90, fontsize=8)    \n",
    "    # Increase the viewing area below the graph\n",
    "    plt.subplots_adjust(bottom=0.3)    \n",
    "    # Add a title and ylabel\n",
    "    plt.title(\"Feature Importance\")\n",
    "    plt.ylabel('Importance')    \n",
    "    feature_importance_plot_path = os.path.join(output_path, \"feature_importance_plot.png\")\n",
    "    plt.savefig(feature_importance_plot_path)\n",
    "    \n",
    "    # Automatically adjust spacing between subplots\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.close()\n",
    "\n",
    "    # Open the images\n",
    "    img1 = Image.open(shap_plot_path)\n",
    "    img2 = Image.open(feature_importance_plot_path)\n",
    "\n",
    "    # Get dimensions\n",
    "    img1_width, img1_height = img1.size\n",
    "    img2_width, img2_height = img2.size\n",
    "\n",
    "    # Create a new image with white background\n",
    "    new_img = Image.new(\"RGB\", (max(img1_width, img2_width), img1_height + img2_height), \"white\")\n",
    "\n",
    "    # Paste the images\n",
    "    new_img.paste(img1, (0, 0))\n",
    "    new_img.paste(img2, (0, img1_height))\n",
    "\n",
    "    # Save the new image\n",
    "    new_img.save(os.path.join(output_path, \"feature_importances.png\"))\n",
    "\n",
    "    # Delete the temporary plots\n",
    "    if os.path.exists(shap_plot_path):\n",
    "        os.remove(shap_plot_path)\n",
    "    if os.path.exists(feature_importance_plot_path):\n",
    "        os.remove(feature_importance_plot_path)    \n",
    "\n",
    "    print(\"Feature importances saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64880851-c785-47f2-90ef-83eaf95822d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
